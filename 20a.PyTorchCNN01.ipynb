{"cells":[{"cell_type":"markdown","metadata":{"id":"QDRW51eYK_pg"},"source":["<hr style=\"color:green\" />\n","<h1 style=\"color:green\">COSC2673 Assignment 2: Image Classification for Cancerous Cells</h1>\n","<h2 style=\"color:green\">File 20: PyTorch First CNN model test on Main data, using AlexNet Config</h2>\n","<hr style=\"color:green\" />\n","\n","<p>\n","In this file, Train a basic Convolutional Neural Network (CNN) with Pytorch, using the AlexNet configuration. The AlexNet configuration contains 5 convolutional layers, 3 max pooling and an average pooling layer, and in the end it has 3 fully-connected layers, the last of which classifies images in 1000 different classes.\n","</p>\n","<p>\n","The CNN implementation from file 10 runs but has terrible precision. Try to fix here\n","</p>"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":539,"status":"ok","timestamp":1683003685462,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"LuaHh7dfK_pj"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n","c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n","c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n","  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision.io import read_image\n"]},{"cell_type":"markdown","metadata":{"id":"4ayZvnueK_pk"},"source":["Configure this script as to whether it runs on Google Colab, or locally"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683003686280,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"vFtUm6uXK_pk"},"outputs":[],"source":["# When on Google Colab, running full training, change both to true. Locally, advised set both to false\n","isGoogleColab = False\n","useFullData = False"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2800,"status":"ok","timestamp":1683003689076,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"zzl3NpfVK_pk","outputId":"fb65a0b0-1895-411a-ff76-8cc7086526e5"},"outputs":[],"source":["# In local, the base directory is the current directory\n","baseDirectory = \"./\"\n","\n","if isGoogleColab:\n","    from google.colab import drive\n","    \n","    # If this is running on Google colab, assume the notebook runs in a \"COSC2673\" folder, which also contains the data files \n","    # in a subfolder called \"image_classification_data\"\n","    drive.mount(\"/content/drive\")\n","    !ls /content/drive/'My Drive'/COSC2673/\n","\n","    # Import the directory so that custom python libraries can be imported\n","    import sys\n","    sys.path.append(\"/content/drive/MyDrive/COSC2673/\")\n","\n","    # Set the base directory to the Google Drive specific folder\n","    baseDirectory = \"/content/drive/MyDrive/COSC2673/\""]},{"cell_type":"markdown","metadata":{"id":"vZCfUn3EK_pl"},"source":["Import the custom python files that contain reusable code"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683003689077,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"beWSdbauK_pl","outputId":"855961c1-7da8-4450-c7b3-3f9e66292cc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Seed: 266305\n"]}],"source":["import data_basic_utility as dbutil\n","import graphing_utility as graphutil\n","import statistics_utility as statsutil\n","\n","import a2_utility as a2util\n","import pytorch_utility as ptutil\n","from pytorch_utility import CancerBinaryDataset\n","from pytorch_utility import CancerCellTypeDataset\n","\n","\n","# randomSeed = dbutil.get_random_seed()\n","randomSeed = 266305\n","print(\"Random Seed: \" + str(randomSeed))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683003689078,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"zgIXX9BXK_pl"},"outputs":[],"source":["# this file should have previously been created in the root directory\n","dfImages = pd.read_csv(baseDirectory + \"images_main.csv\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683003689078,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"6_WFGagHK_pl","outputId":"f1ca6c45-d622-4dd2-91cb-adbd202a8b26"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>ImageName</th>\n","      <th>isCancerous</th>\n","      <th>cellType</th>\n","      <th>trainValTest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>./Image_classification_data/patch_images\\1.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>./Image_classification_data/patch_images\\10.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>./Image_classification_data/patch_images\\1000.png</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>./Image_classification_data/patch_images\\10000...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>./Image_classification_data/patch_images\\10001...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                          ImageName  isCancerous  \\\n","0      0     ./Image_classification_data/patch_images\\1.png            0   \n","1      1    ./Image_classification_data/patch_images\\10.png            0   \n","2      3  ./Image_classification_data/patch_images\\1000.png            1   \n","3      4  ./Image_classification_data/patch_images\\10000...            0   \n","4      5  ./Image_classification_data/patch_images\\10001...            0   \n","\n","   cellType  trainValTest  \n","0         0             0  \n","1         0             0  \n","2         2             0  \n","3         1             0  \n","4         1             0  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Get The training Split and the Validation Split\n","dfImagesTrain = dfImages[dfImages[\"trainValTest\"] == 0].reset_index()\n","dfImagesVal = dfImages[dfImages[\"trainValTest\"] == 1].reset_index()\n","\n","dfImagesTrain.head()"]},{"cell_type":"markdown","metadata":{"id":"TZ1R94YdK_pn"},"source":["Note: The definition of the Custom Datasets for both the isCancerous data and the Cell Type data are defined in the pytorch_utility.py file.\n","\n","Also, rather than loading all the training images and calculating the mean and standard deviation values in here, that was run separately in file 05a.PyTorchGetMeanAndStd.ipynb\n","\n","Here we can just define the values to use, which shouldn't change unless the data is reloaded and a new train/validation/test split is generated"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.8035, 0.5909, 0.7640])\n","tensor([0.1246, 0.1947, 0.1714])\n"]}],"source":["train_mean, train_std = ptutil.getTrainMeanAndStdTensors()\n","print(train_mean)\n","print(train_std)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683003705777,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"I8z3yX8ZK_pn"},"outputs":[],"source":["# Create a tranform operation that also normalizes the images according to the mean and standard deviations of the images\n","transform_normalize = transforms.Compose(\n","    [transforms.ToPILImage(),\n","    transforms.ToTensor(), \n","    transforms.Normalize(train_mean, train_std)])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683003705777,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"qb_33dFmK_pn"},"outputs":[],"source":["cancerous_training_data = None\n","\n","# Create a custom Dataset for the training and validation data\n","if useFullData:\n","    cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n","else:\n","    # For testing in a small dataset\n","    dfImagesTrainTest = dfImagesTrain.iloc[range(100), :].reset_index()\n","    cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrainTest, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","cancerous_validation_data = CancerBinaryDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","# Create data loaders\n","cancerous_train_dataloader = DataLoader(cancerous_training_data, batch_size=32, shuffle=True, num_workers=2)\n","cancerous_val_dataloader = DataLoader(cancerous_validation_data, batch_size=32, shuffle=True, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"F4jD7E2PK_po"},"source":["Now, create a class for the AlexNet style Convolutional Neural Netowrk. For this basic NN, we will use 3 fully connected layers. The number of features in this will be 27 x 27 x 3, or 2187.\n","\n","The AlexNet configuration contains 5 convolutional layers, 3 max pooling and an average pooling layer, and in the end it has 3 fully-connected layers, the last of which classifies images in 1000 different classes.\n","\n","In this, we will use the **ReLU** Activation Function. This is the Rectified Linear Unit function, which allows the function to become non-linear.\n","\n","Remember that each pooling layer halves both the height and the width of the image, so by using 2 pooling layers, the height and width are 1/4 of the original sizes. "]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683003705778,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"0two1S9gK_po"},"outputs":[],"source":["# Create a class for the Neural Network\n","class PT_CNN_AlexNet_IsCancerous(nn.Module):\n","\n","    # In the constructor, initialize the layers to use\n","    def __init__(self):\n","        super(PT_CNN_AlexNet_IsCancerous, self).__init__()\n","\n","        # first, define the subsampling methods. Though they are used multiple times, these are the\n","        # operations, so only need to be defined once\n","        # Note: added a second max pooling operation with padding 1 to fix some output sizing issue\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","\n","        # define the ReLU Activation method to use\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # define the convolution layers\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=11, stride=4, padding=2)\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n","        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n","        \n","        # define the fully connected neural layers\n","        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc3 = nn.Linear(4096, 2)\n","\n","    # Create the forward function, which is used in training\n","    def forward(self, x):\n","\n","        # print(\"Init Shape: \" + str(x.shape))\n","\n","        # Process the first 2 convolution layers, applying maxpooling\n","        x = self.relu(self.conv1(x))\n","        x = self.maxpool(x)\n","        x = self.relu(self.conv2(x))\n","        x = self.maxpool2(x)\n","        \n","        # Then process the remaining convolution layers without any pooling\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = self.relu(self.conv5(x))\n","\n","        # Then apply a max pool and average pool on the result\n","        x = self.maxpool2(x)\n","        x = self.avgpool(x)\n","\n","        # This should convert to tensors that are acceptable for the input into the NN 3 layers\n","        x = x.view(x.size(0), 256 * 6 * 6)\n","\n","        # Now process the 3 layers of the Fully Connected NN\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))        \n","\n","        # return the result\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"pO5dPhy6K_po"},"source":["Now train the CNN Model.\n","\n","During training, we will use the following:\n","- Softmax Cross Entropy Loss as our Loss function. This is a good Loss function that basically converts scores for each class into probabilities\n","- The Adam Optimizer, which is a version of Gradient Descent\n","- Initially, just 10 epochs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272396,"status":"ok","timestamp":1683003978169,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"vQUAMyGuK_po","outputId":"d7e13864-910e-4876-d2c0-7ddfa9205ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting Epoch 0...\n","Starting Epoch 1...\n","Starting Epoch 2...\n","Starting Epoch 3...\n","Starting Epoch 4...\n","Starting Epoch 5...\n","Starting Epoch 6...\n","Starting Epoch 7...\n","Starting Epoch 8...\n","Starting Epoch 9...\n"]}],"source":["# set the Learning Rate to use\n","learning_rate = 0.0001\n","epochsToUse = 10\n","\n","net = PT_CNN_AlexNet_IsCancerous()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","for epoch in range(epochsToUse):\n","    print(\"Starting Epoch \" + str(epoch) + \"...\")\n","    for i, data in enumerate(cancerous_train_dataloader, 0):\n","        # Get the inputs\n","        inputs, labels = data\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Perform Forward and Backward propagation then optimize the weights\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"CEB7hSkAK_po"},"source":["Training Time in Nelson's Local Environment on the full data takes a very long time, stopped after 100 minutes. This will need to be done in Colab.\n","\n","Now Predict according to the validation data and evaluate. While looping through here, we will need to get out the Labels from the data loader, because the order of predictions in the batches do not match the order of the original Target values in the dataset (because we turned Shuffle on)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2303,"status":"ok","timestamp":1683003980462,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"ithF1bLMK_pp","outputId":"88df93de-4c98-4fcd-c60a-e9e218642bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["The testing set accuracy of the isCancerous Classification Network is 39.57322987390883%\n"]}],"source":["correct, total = 0,  0\n","predictions = []\n","\n","# Set the Neural Network into evaluation (test) mode\n","net.eval()\n","\n","step=0\n","\n","y_val_cancerous = []\n","y_val_pred_cancerous = []\n","\n","# Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n","for i, data in enumerate(cancerous_val_dataloader, 0):\n","    inputs, labels = data\n","\n","    outputs = net(inputs)\n","    _, predicted = torch.max(outputs.data, 1)\n","\n","    # Loop through the batch, build the lists of the raw label and prediction values\n","    for j in range(len(labels)):\n","        y_val_cancerous.append(labels[j].item())\n","        y_val_pred_cancerous.append(predicted[j].item())\n","\n","    predictions.append(predicted)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","\n","accuracy = (correct/total) * 100\n","print(\"The testing set accuracy of the isCancerous Classification Network is \" + str(accuracy) + \"%\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683003980462,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"zTfShcFRK_pp","outputId":"40ada62a-46c8-40e6-da18-cb2f532f129c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","33\n"]}],"source":["for i in range(3):\n","    print(predictions[i])\n","\n","print(len(predictions))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683003980463,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"rF-DYPECK_pp","outputId":"769e29da-b592-4223-eef2-007472360fc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels\n","1\n","0\n","1\n","1\n","0\n","Predictions\n","0\n","0\n","0\n","0\n","0\n"]}],"source":["# y_val_pred_cancerous = [item for sublist in y_val_pred_cancerous for item in sublist]\n","print(\"Labels\")\n","for i in range(5):\n","    print(y_val_cancerous[i])\n","\n","print(\"Predictions\")\n","for i in range(5):\n","    print(y_val_pred_cancerous[i])"]},{"cell_type":"markdown","metadata":{"id":"fpeojAsaK_pp"},"source":["Convert these results into a confusion matrix and then get an F1 Score for comparison"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683003980463,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"8P0V6pHLK_pp","outputId":"7360014e-a0a6-49a7-979b-b7e1c3f3e015"},"outputs":[{"name":"stdout","output_type":"stream","text":["Binary Classification Results for isCancerous Predictions\n","              precision    recall  f1-score   support\n","\n","           0       0.40      1.00      0.57       408\n","           1       0.00      0.00      0.00       623\n","\n","    accuracy                           0.40      1031\n","   macro avg       0.20      0.50      0.28      1031\n","weighted avg       0.16      0.40      0.22      1031\n","\n","- Accuracy Score: 0.3957322987390883\n","- Precision Score: 0.0\n","- Recall Score: 0.0\n","- F1 Score: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# assuming predictions is just a list of predicted values\n","cm = confusion_matrix(y_val_cancerous, y_val_pred_cancerous)\n","\n","print(\"Binary Classification Results for isCancerous Predictions\")\n","print(classification_report(y_val_cancerous, y_val_pred_cancerous))\n","print(\"- Accuracy Score: \" + str(accuracy_score(y_val_cancerous, y_val_pred_cancerous)))\n","print(\"- Precision Score: \" + str(precision_score(y_val_cancerous, y_val_pred_cancerous)))\n","print(\"- Recall Score: \" + str(recall_score(y_val_cancerous, y_val_pred_cancerous)))\n","print(\"- F1 Score: \" + str(f1_score(y_val_cancerous, y_val_pred_cancerous)))"]},{"cell_type":"markdown","metadata":{"id":"rvbiQyfWYEZu"},"source":["**Results for 10 epochs**\n","\n","Todo"]},{"cell_type":"markdown","metadata":{"id":"DHozRzzdK_pq"},"source":["Now also train a model for CellType Predictions"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683003980463,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"AVvBdxxjK_pq","outputId":"a96d3bad-6bd3-43aa-9a18-3e82aa847b77"},"outputs":[],"source":["# Create a custom Dataset for the training and validation data\n","celltype_training_data = CancerCellTypeDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n","celltype_validation_data = CancerCellTypeDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize)\n","\n","# Create data loaders\n","celltype_train_dataloader = DataLoader(celltype_training_data, batch_size=32, shuffle=True, num_workers=4)\n","celltype_val_dataloader = DataLoader(celltype_validation_data, batch_size=32, shuffle=True, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"fd9XOjhpK_pq"},"source":["Create a class for the Cell Type Neural Network model. The structure of the class will be fundamentally the same, only the model will need to output 4 classes"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683003980464,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"eKOxU2-4K_pq"},"outputs":[],"source":["# Create a class for the Neural Network\n","class PT_CNN_AlexNet_CellType(nn.Module):\n","\n","    # In the constructor, initialize the layers to use\n","    def __init__(self):\n","        super(PT_CNN_AlexNet_CellType, self).__init__()\n","\n","        # first, define the subsampling methods. Though they are used multiple times, these are the\n","        # operations, so only need to be defined once\n","        # Note: added a second max pooling operation with padding 1 to fix some output sizing issue\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","\n","        # define the ReLU Activation method to use\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # define the convolution layers\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2)\n","        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2)\n","        self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=1)\n","        self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n","        \n","        # define the fully connected neural layers\n","        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc3 = nn.Linear(4096, 4)\n","\n","    # Create the forward function, which is used in training\n","    def forward(self, x):\n","\n","        # print(\"Init Shape: \" + str(x.shape))\n","\n","        # Process the first 2 convolution layers, applying maxpooling\n","        x = self.relu(self.conv1(x))\n","        x = self.maxpool(x)\n","        x = self.relu(self.conv2(x))\n","        x = self.maxpool2(x)\n","        \n","        # Then process the remaining convolution layers without any pooling\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = self.relu(self.conv5(x))\n","\n","        # Then apply a max pool and average pool on the result\n","        x = self.maxpool2(x)\n","        x = self.avgpool(x)\n","\n","        # This should convert to tensors that are acceptable for the input into the NN 3 layers\n","        x = x.view(x.size(0), 256 * 6 * 6)\n","\n","        # Now process the 3 layers of the Fully Connected NN\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))        \n","\n","        # return the result\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"KRU0R9EMK_pq"},"source":["Now train the Fully Connected Neural Network Model. Use the same configuration (objective function, optimizer etc) as the Binary Classifier"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3FjNKScK_pq","outputId":"a741ad36-242b-40a6-ab2e-5cdb215fc283"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting Epoch 0...\n","Starting Epoch 1...\n","Starting Epoch 2...\n","Starting Epoch 3...\n","Starting Epoch 4...\n","Starting Epoch 5...\n","Starting Epoch 6...\n","Starting Epoch 7...\n"]}],"source":["# # set the Learning Rate to use\n","# learning_rate = 0.0001\n","# epochsToUse = 10\n","\n","# net = PT_CNN_AlexNet_CellType()\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","# for epoch in range(epochsToUse):\n","#     print(\"Starting Epoch \" + str(epoch) + \"...\")\n","#     for i, data in enumerate(celltype_train_dataloader, 0):\n","#         # Get the inputs\n","#         inputs, labels = data\n","\n","#         # Zero the parameter gradients\n","#         optimizer.zero_grad()\n","\n","#         # Perform Forward and Backward propagation then optimize the weights\n","#         outputs = net(inputs)\n","#         loss = criterion(outputs, labels)\n","#         loss.backward()\n","#         optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"NpLNiit9K_pr"},"source":["Predict on the Validation data and evaluate the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfU8z2ljK_pr"},"outputs":[],"source":["# correct, total = 0,  0\n","# predictions = []\n","\n","# # Set the Neural Network into evaluation (test) mode\n","# net.eval()\n","\n","# step=0\n","\n","# y_val_celltype = []\n","# y_val_pred_celltype = []\n","\n","# # Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n","# for i, data in enumerate(celltype_val_dataloader, 0):\n","#     inputs, labels = data\n","\n","#     # This should convert the image tensors into vectors\n","#     inputs = inputs.view(-1, 27 * 27 * 3)\n","\n","#     outputs = net(inputs)\n","#     _, predicted = torch.max(outputs.data, 1)\n","    \n","#     # print(labels)\n","#     # print(predicted)  \n","#     # print(len(labels))\n","#     # print(len(predicted))\n","\n","#     # Loop through the batch, build the lists of the raw label and prediction values\n","#     for j in range(len(labels)):\n","#         y_val_celltype.append(labels[j].item())\n","#         y_val_pred_celltype.append(predicted[j].item())\n","\n","#     predictions.append(predicted)\n","#     total += labels.size(0)\n","#     correct += (predicted == labels).sum().item()\n","\n","\n","# accuracy = (correct/total) * 100\n","# print(\"The testing set accuracy of the CellType Classification Network is \" + str(accuracy) + \"%\")"]},{"cell_type":"markdown","metadata":{"id":"cmVaP2YMK_pr"},"source":["Convert these results into a confusion matrix and then get an F1 Score for comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dW7wQLRZK_pr"},"outputs":[],"source":["# # assuming predictions is just a list of predicted values\n","# cm = confusion_matrix(y_val_celltype, y_val_pred_celltype)\n","\n","# print(\"CellType Multi-class Classification Results for Cell Type Predictions\")\n","# print(classification_report(y_val_celltype, y_val_pred_celltype))\n","# print(\"- Accuracy Score: \" + str(accuracy_score(y_val_celltype, y_val_pred_celltype)))\n","# print(\"- Precision Score: \" + str(precision_score(y_val_celltype, y_val_pred_celltype, average=\"micro\")))\n","# print(\"- Recall Score: \" + str(recall_score(y_val_celltype, y_val_pred_celltype, average=\"micro\")))\n","# print(\"- F1 Score: \" + str(f1_score(y_val_celltype, y_val_pred_celltype, average=\"micro\")))"]},{"cell_type":"markdown","metadata":{"id":"adr2TddpTyYY"},"source":["**Results for 10 epochs:**\n","\n","Todo"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"dcbc78149e46ccbab92a3f68a48c52feb0796c7e10dad8e3f1a2a5a780973376"}}},"nbformat":4,"nbformat_minor":0}
