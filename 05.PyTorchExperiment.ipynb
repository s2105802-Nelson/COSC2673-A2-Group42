{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:green\" />\n",
    "<h1 style=\"color:green\">COSC2673 Assignment 2: Image Classification for Cancerous Cells</h1>\n",
    "<h2 style=\"color:green\">File 03: Basic PyTorch Fully Connected Neural Network model test on Main data</h2>\n",
    "<hr style=\"color:green\" />\n",
    "\n",
    "<p>\n",
    "In this file, in order to check how long training might take, do a quick train of an NN just on 200 images, or 1000 images\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\nelso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import data_basic_utility as dbutil\n",
    "import graphing_utility as graphutil\n",
    "import statistics_utility as statsutil\n",
    "import a2_utility as a2util\n",
    "\n",
    "randomSeed = dbutil.get_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfImages = pd.read_csv(\"images_main.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "      <th>cellType</th>\n",
       "      <th>trainValTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Image_classification_data/patch_images\\1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Image_classification_data/patch_images\\10.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Image_classification_data/patch_images\\1000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Image_classification_data/patch_images\\10000...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./Image_classification_data/patch_images\\10001...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName  isCancerous  cellType  \\\n",
       "0     ./Image_classification_data/patch_images\\1.png            0         0   \n",
       "1    ./Image_classification_data/patch_images\\10.png            0         0   \n",
       "3  ./Image_classification_data/patch_images\\1000.png            1         2   \n",
       "4  ./Image_classification_data/patch_images\\10000...            0         1   \n",
       "5  ./Image_classification_data/patch_images\\10001...            0         1   \n",
       "\n",
       "   trainValTest  \n",
       "0             0  \n",
       "1             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get The training Split and the Validation Split\n",
    "dfImagesTrain = dfImages[dfImages[\"trainValTest\"] == 0]\n",
    "dfImagesVal = dfImages[dfImages[\"trainValTest\"] == 1]\n",
    "\n",
    "dfImagesTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into a numpy array. This is so we can find the mean and std of the RBG values in order to Normalize the images for the Neural Network\n",
    "imgsTrain = []\n",
    "for imageName in dfImagesTrain[\"ImageName\"]:\n",
    "    img = cv2.imread(imageName)\n",
    "    imgsTrain.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.8035, 0.5909, 0.7640])\n",
      "Standard deviation: tensor([0.1246, 0.1947, 0.1714])\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to convert images to PyTorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Convert images to tensors and concatenate them into a single tensor\n",
    "tensor_images = torch.cat([transform(img).unsqueeze(0) for img in imgsTrain])\n",
    "\n",
    "# Calculate the mean and standard deviation of the tensor values\n",
    "train_mean = tensor_images.mean(dim=(0, 2, 3))\n",
    "train_std = tensor_images.std(dim=(0, 2, 3))\n",
    "\n",
    "print(\"Mean:\", train_mean)\n",
    "print(\"Standard deviation:\", train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerBinaryDataset(Dataset):\n",
    "    def __init__(self, dfImages, img_dir, transform=None, target_transform=None): \n",
    "        self.df_images = dfImages\n",
    "        self.img_labels = dfImages[\"isCancerous\"]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df_images.loc[idx, \"ImageName\"])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tranform operation that also normalizes the images according to the mean and standard deviations of the images\n",
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(train_mean, train_std)])\n",
    "\n",
    "# transform_normalize = transforms.Compose([transforms.Normalize(train_mean, train_std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a test data loader with just a few records, to see how quickly it trains locally\n",
    "# Create a custom Dataset for the \n",
    "dfImagesTrain_test = dfImagesTrain.iloc[range(1000), :].reset_index()\n",
    "\n",
    "train_testing_data = CancerBinaryDataset(dfImagesTrain_test, \"./\", transform=transform_normalize)\n",
    "\n",
    "# Create data loaders\n",
    "train_testing_dataloader = DataLoader(train_testing_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "# train_features, train_labels = next(iter(train_testing_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")\n",
    "\n",
    "# Not working, \"TypeError: Invalid shape (3, 27, 27) for image data\"\n",
    "# But that's okay, don't think we need to display the image in this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for the training and validation data\n",
    "training_data = CancerBinaryDataset(dfImagesTrain, \"./\", transform=transform_normalize)\n",
    "validation_data = CancerBinaryDataset(dfImagesVal, \"./\", transform=transform_normalize)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(training_data, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a class for the basic, Fully Connected Neural Network. For this basic NN, we will use 3 fully connected layers. The number of features in this will be 27 x 27 x 3, or 2187.\n",
    "\n",
    "Layer 1: Input is the images, which are 27 x 27 pixels, with 3 color values (RGB). Experiment initially with 1458 nodes\n",
    "Layer 2: Input is 1458 from the the previous layer, down to 729\n",
    "Layer 3: Input is 729 from the the previous layer, since this is a binary classification problem, the output will be 2 classes\n",
    "\n",
    "In this, we will use the **ReLU** Activation Function. This is the Rectified Linear Unit function, which allows the function to become non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for the Neural Network\n",
    "class PT_NN_IsCancerous(nn.Module):\n",
    "\n",
    "    # In the constructor, initialize the layers to use\n",
    "    def __init__(self):\n",
    "        super(PT_NN_IsCancerous, self).__init__()\n",
    "        self.fc1 = nn.Linear(27 * 27 * 3, 1458)\n",
    "        self.fc2 = nn.Linear(1458, 729)\n",
    "        self.fc3 = nn.Linear(729, 2)\n",
    "\n",
    "    # Create the forward function, which is used in training\n",
    "    def forward(self, x):\n",
    "        # process through each layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # return the result\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the NN, just using the test training segment (this is just 50 images). This is just to see how quickly it runs in this environment.\n",
    "\n",
    "During training, we will use the following:\n",
    "- Softmax Cross Entropy Loss as our Loss function. This is a good Loss function that basically converts scores for each class into probabilities\n",
    "- The Adam Optimizer, which is a version of Gradient Descent\n",
    "- Initially, just 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the Learning Rate to use\n",
    "learning_rate = 0.0001\n",
    "epochsToUse = 10\n",
    "\n",
    "net = PT_NN_IsCancerous()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochsToUse):\n",
    "    for i, data in enumerate(train_testing_dataloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # This should convert the image tensors into vectors\n",
    "        inputs = inputs.view(-1, 27 * 27 * 3)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform Forward and Backward propagation then optimize the weights\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on 200 images seems to take 3 seconds (locally on Nelson's computer). 1000 takes about 17 seconds\n",
    "\n",
    "So if we train locally on 10,000 images. Maybe 150 seconds, or about 3 min?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcbc78149e46ccbab92a3f68a48c52feb0796c7e10dad8e3f1a2a5a780973376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
