{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:green\" />\n",
    "<h1 style=\"color:green\">COSC2673 Assignment 2: Image Classification for Cancerous Cells</h1>\n",
    "<h2 style=\"color:green\">File 03: Basic PyTorch Fully Connected Neural Network model test on Main data</h2>\n",
    "<hr style=\"color:green\" />\n",
    "\n",
    "<p>\n",
    "In this file, Train a basic fully connected NN with Pytorch, using a basic 3 layer configuration\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io import read_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure this script as to whether it runs on Google Colab, or locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "isGoogleColab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In local, the base directory is the current directory\n",
    "baseDirectory = \"./\"\n",
    "\n",
    "if isGoogleColab:\n",
    "    from google.colab import drive\n",
    "    \n",
    "    # If this is running on Google colab, assume the notebook runs in a \"COSC2673\" folder, which also contains the data files \n",
    "    # in a subfolder called \"image_classification_data\"\n",
    "    drive.mount(\"/content/drive\")\n",
    "    !ls /content/drive/'My Drive'/COSC2673/\n",
    "\n",
    "    # Import the directory so that custom python libraries can be imported\n",
    "    import sys\n",
    "    sys.path.append(\"/content/drive/MyDrive/COSC2673/\")\n",
    "\n",
    "    # Set the base directory to the Google Drive specific folder\n",
    "    baseDirectory = \"/content/drive/MyDrive/COSC2673/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the custom python files that contain reusable code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_basic_utility as dbutil\n",
    "import graphing_utility as graphutil\n",
    "import statistics_utility as statsutil\n",
    "\n",
    "import a2_utility as a2util\n",
    "import pytorch_utility as ptutil\n",
    "from pytorch_utility import CancerBinaryDataset\n",
    "from pytorch_utility import CancerCellTypeDataset\n",
    "\n",
    "randomSeed = dbutil.get_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file should have previously been created in the root directory\n",
    "dfImages = pd.read_csv(baseDirectory + \"images_main.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "      <th>cellType</th>\n",
       "      <th>trainValTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./Image_classification_data/patch_images\\1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./Image_classification_data/patch_images\\10.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>./Image_classification_data/patch_images\\1000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>./Image_classification_data/patch_images\\10000...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>./Image_classification_data/patch_images\\10001...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          ImageName  isCancerous  \\\n",
       "0      0     ./Image_classification_data/patch_images\\1.png            0   \n",
       "1      1    ./Image_classification_data/patch_images\\10.png            0   \n",
       "2      3  ./Image_classification_data/patch_images\\1000.png            1   \n",
       "3      4  ./Image_classification_data/patch_images\\10000...            0   \n",
       "4      5  ./Image_classification_data/patch_images\\10001...            0   \n",
       "\n",
       "   cellType  trainValTest  \n",
       "0         0             0  \n",
       "1         0             0  \n",
       "2         2             0  \n",
       "3         1             0  \n",
       "4         1             0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get The training Split and the Validation Split\n",
    "dfImagesTrain = dfImages[dfImages[\"trainValTest\"] == 0].reset_index()\n",
    "dfImagesVal = dfImages[dfImages[\"trainValTest\"] == 1].reset_index()\n",
    "\n",
    "dfImagesTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into a numpy array. This is so we can find the mean and std of the RBG values in order to Normalize the images for the Neural Network\n",
    "imgsTrain = []\n",
    "for imageName in dfImagesTrain[\"ImageName\"]:\n",
    "    # In colab, we want to remove the leading \"./\" from the image name\n",
    "    if isGoogleColab:\n",
    "        if imageName.startswith(\"./\"):\n",
    "            imageName = imageName[2:]\n",
    "\n",
    "    imageName = imageName.replace(\"\\\\\", \"/\")\n",
    "    img = cv2.imread(baseDirectory + imageName)\n",
    "    imgsTrain.append(img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imgsTrain))\n",
    "# print(imgsTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.8035, 0.5909, 0.7640])\n",
      "Standard deviation: tensor([0.1246, 0.1947, 0.1714])\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to convert images to PyTorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Convert images to tensors and concatenate them into a single tensor\n",
    "tensor_images = torch.cat([transform(img).unsqueeze(0) for img in imgsTrain])\n",
    "\n",
    "# Calculate the mean and standard deviation of the tensor values\n",
    "train_mean = tensor_images.mean(dim=(0, 2, 3))\n",
    "train_std = tensor_images.std(dim=(0, 2, 3))\n",
    "\n",
    "print(\"Mean:\", train_mean)\n",
    "print(\"Standard deviation:\", train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The definition of the Custom Datasets for both the isCancerous data and the Cell Type data are defined in the pytorch_utility.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tranform operation that also normalizes the images according to the mean and standard deviations of the images\n",
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(train_mean, train_std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing in a small dataset\n",
    "dfImagesTrainTest = dfImagesTrain.iloc[range(1000), :].reset_index()\n",
    "cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrainTest, baseDirectory, transform=transform_normalize, target_transform=None)\n",
    "\n",
    "# Create a custom Dataset for the training and validation data\n",
    "# cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n",
    "cancerous_validation_data = CancerBinaryDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize, target_transform=None)\n",
    "\n",
    "# Create data loaders\n",
    "cancerous_train_dataloader = DataLoader(cancerous_training_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "cancerous_val_dataloader = DataLoader(cancerous_validation_data, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a class for the basic, Fully Connected Neural Network. For this basic NN, we will use 3 fully connected layers. The number of features in this will be 27 x 27 x 3, or 2187.\n",
    "\n",
    "Layer 1: Input is the images, which are 27 x 27 pixels, with 3 color values (RGB). Experiment initially with 1458 nodes\n",
    "Layer 2: Input is 1458 from the the previous layer, down to 729\n",
    "Layer 3: Input is 729 from the the previous layer, since this is a binary classification problem, the output will be 2 classes\n",
    "\n",
    "In this, we will use the **ReLU** Activation Function. This is the Rectified Linear Unit function, which allows the function to become non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for the Neural Network\n",
    "class PT_NN_IsCancerous(nn.Module):\n",
    "\n",
    "    # In the constructor, initialize the layers to use\n",
    "    def __init__(self):\n",
    "        super(PT_NN_IsCancerous, self).__init__()\n",
    "        self.fc1 = nn.Linear(27 * 27 * 3, 1458)\n",
    "        self.fc2 = nn.Linear(1458, 729)\n",
    "        self.fc3 = nn.Linear(729, 2)\n",
    "\n",
    "    # Create the forward function, which is used in training\n",
    "    def forward(self, x):\n",
    "        # process through each layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # return the result\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the Fully Connected Neural Network Model.\n",
    "\n",
    "During training, we will use the following:\n",
    "- Softmax Cross Entropy Loss as our Loss function. This is a good Loss function that basically converts scores for each class into probabilities\n",
    "- The Adam Optimizer, which is a version of Gradient Descent\n",
    "- Initially, just 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0...\n",
      "Starting Epoch 1...\n",
      "Starting Epoch 2...\n",
      "Starting Epoch 3...\n",
      "Starting Epoch 4...\n",
      "Starting Epoch 5...\n",
      "Starting Epoch 6...\n",
      "Starting Epoch 7...\n",
      "Starting Epoch 8...\n",
      "Starting Epoch 9...\n"
     ]
    }
   ],
   "source": [
    "# set the Learning Rate to use\n",
    "learning_rate = 0.0001\n",
    "epochsToUse = 10\n",
    "\n",
    "net = PT_NN_IsCancerous()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochsToUse):\n",
    "    print(\"Starting Epoch \" + str(epoch) + \"...\")\n",
    "    for i, data in enumerate(cancerous_train_dataloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # This should convert the image tensors into vectors\n",
    "        inputs = inputs.view(-1, 27 * 27 * 3)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform Forward and Backward propagation then optimize the weights\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Time in Nelson's Local Environment on the full data takes a very long time, stopped after 100 minutes. This will need to be done in Colab.\n",
    "\n",
    "Now Predict according to the validation data and evaluate. While looping through here, we will need to get out the Labels from the data loader, because the order of predictions in the batches do not match the order of the original Target values in the dataset (because we turned Shuffle on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the isCancerous Classification Network is 83.70514064015518%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0,  0\n",
    "predictions = []\n",
    "\n",
    "# Set the Neural Network into evaluation (test) mode\n",
    "net.eval()\n",
    "\n",
    "step=0\n",
    "\n",
    "y_val_cancerous = []\n",
    "y_pred_cancerous = []\n",
    "\n",
    "# Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n",
    "for i, data in enumerate(cancerous_val_dataloader, 0):\n",
    "    inputs, labels = data\n",
    "\n",
    "\n",
    "    # This should convert the image tensors into vectors\n",
    "    inputs = inputs.view(-1, 27 * 27 * 3)\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # print(labels)\n",
    "    # print(predicted)  \n",
    "    # print(len(labels))\n",
    "    # print(len(predicted))\n",
    "\n",
    "    # Loop through the batch, build the lists of the raw label and prediction values\n",
    "    for j in range(len(labels)):\n",
    "        y_val_cancerous.append(labels[j].item())\n",
    "        y_pred_cancerous.append(predicted[j].item())\n",
    "\n",
    "    predictions.append(predicted)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "accuracy = (correct/total) * 100\n",
    "print(\"The testing set accuracy of the isCancerous Classification Network is \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0])\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(predictions[i])\n",
    "\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "Predictions\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# y_pred_cancerous = [item for sublist in y_pred_cancerous for item in sublist]\n",
    "print(\"Labels\")\n",
    "for i in range(5):\n",
    "    print(y_val_cancerous[i])\n",
    "\n",
    "print(\"Predictions\")\n",
    "for i in range(5):\n",
    "    print(y_pred_cancerous[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert these results into a confusion matrix and then get an F1 Score for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Results for isCancerous Predictions\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78       408\n",
      "           1       0.84      0.91      0.87       623\n",
      "\n",
      "    accuracy                           0.84      1031\n",
      "   macro avg       0.84      0.82      0.83      1031\n",
      "weighted avg       0.84      0.84      0.83      1031\n",
      "\n",
      "F1 Score: 0.8705701078582435\n"
     ]
    }
   ],
   "source": [
    "# assuming predictions is just a list of predicted values\n",
    "cm = confusion_matrix(y_val_cancerous, y_pred_cancerous)\n",
    "\n",
    "print(\"Binary Classification Results for isCancerous Predictions\")\n",
    "print(classification_report(y_val_cancerous, y_pred_cancerous))\n",
    "print(\"F1 Score: \" + str(f1_score(y_val_cancerous, y_pred_cancerous)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now also train a model for CellType Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for the training and validation data\n",
    "celltype_training_data = CancerCellTypeDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n",
    "celltype_validation_data = CancerCellTypeDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize)\n",
    "\n",
    "# Create data loaders\n",
    "celltype_train_dataloader = DataLoader(celltype_training_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "celltype_val_dataloader = DataLoader(celltype_validation_data, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class for the Cell Type Neural Network model. The structure of the class will be fundamentally the same, only the model will need to output 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for the Neural Network\n",
    "class PT_NN_CellType(nn.Module):\n",
    "\n",
    "    # In the constructor, initialize the layers to use\n",
    "    def __init__(self):\n",
    "        super(PT_NN_CellType, self).__init__()\n",
    "        self.fc1 = nn.Linear(27 * 27 * 3, 1458)\n",
    "        self.fc2 = nn.Linear(1458, 729)\n",
    "        self.fc3 = nn.Linear(729, 4)\n",
    "\n",
    "    # Create the forward function, which is used in training\n",
    "    def forward(self, x):\n",
    "        # process through each layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # return the result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the Fully Connected Neural Network Model. Use the same configuration (objective function, optimizer etc) as the Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0...\n",
      "Starting Epoch 1...\n",
      "Starting Epoch 2...\n",
      "Starting Epoch 3...\n",
      "Starting Epoch 4...\n",
      "Starting Epoch 5...\n",
      "Starting Epoch 6...\n",
      "Starting Epoch 7...\n",
      "Starting Epoch 8...\n",
      "Starting Epoch 9...\n"
     ]
    }
   ],
   "source": [
    "# set the Learning Rate to use\n",
    "learning_rate = 0.0001\n",
    "epochsToUse = 10\n",
    "\n",
    "net = PT_NN_CellType()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochsToUse):\n",
    "    print(\"Starting Epoch \" + str(epoch) + \"...\")\n",
    "    for i, data in enumerate(celltype_train_dataloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # This should convert the image tensors into vectors\n",
    "        inputs = inputs.view(-1, 27 * 27 * 3)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform Forward and Backward propagation then optimize the weights\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the Validation data and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the CellType Classification Network is 75.55771096023278%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0,  0\n",
    "predictions = []\n",
    "\n",
    "# Set the Neural Network into evaluation (test) mode\n",
    "net.eval()\n",
    "\n",
    "step=0\n",
    "\n",
    "y_val_celltype = []\n",
    "y_pred_celltype = []\n",
    "\n",
    "# Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n",
    "for i, data in enumerate(celltype_val_dataloader, 0):\n",
    "    inputs, labels = data\n",
    "\n",
    "    # This should convert the image tensors into vectors\n",
    "    inputs = inputs.view(-1, 27 * 27 * 3)\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # print(labels)\n",
    "    # print(predicted)  \n",
    "    # print(len(labels))\n",
    "    # print(len(predicted))\n",
    "\n",
    "    # Loop through the batch, build the lists of the raw label and prediction values\n",
    "    for j in range(len(labels)):\n",
    "        y_val_celltype.append(labels[j].item())\n",
    "        y_pred_celltype.append(predicted[j].item())\n",
    "\n",
    "    predictions.append(predicted)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "accuracy = (correct/total) * 100\n",
    "print(\"The testing set accuracy of the CellType Classification Network is \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert these results into a confusion matrix and then get an F1 Score for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellType Multi-class Classification Results for Cell Type Predictions\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58       155\n",
      "           1       0.60      0.79      0.68       185\n",
      "           2       0.91      0.86      0.88       623\n",
      "           3       0.15      0.10      0.12        68\n",
      "\n",
      "    accuracy                           0.76      1031\n",
      "   macro avg       0.56      0.58      0.57      1031\n",
      "weighted avg       0.76      0.76      0.75      1031\n",
      "\n",
      "F1 Score: 0.7555771096023278\n"
     ]
    }
   ],
   "source": [
    "# assuming predictions is just a list of predicted values\n",
    "cm = confusion_matrix(y_val_celltype, y_pred_celltype)\n",
    "\n",
    "print(\"CellType Multi-class Classification Results for Cell Type Predictions\")\n",
    "print(classification_report(y_val_celltype, y_pred_celltype))\n",
    "print(\"F1 Score: \" + str(f1_score(y_val_celltype, y_pred_celltype, average=\"micro\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcbc78149e46ccbab92a3f68a48c52feb0796c7e10dad8e3f1a2a5a780973376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
