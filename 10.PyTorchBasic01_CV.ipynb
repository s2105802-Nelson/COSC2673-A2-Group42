{"cells":[{"cell_type":"markdown","metadata":{"id":"QDRW51eYK_pg"},"source":["<hr style=\"color:green\" />\n","<h1 style=\"color:green\">COSC2673 Assignment 2: Image Classification for Cancerous Cells</h1>\n","<h2 style=\"color:green\">File 10: Basic PyTorch FC-NN with Cross Valiation</h2>\n","<hr style=\"color:green\" />\n","\n","<p>\n","In this file, Train a basic fully connected NN with Pytorch, using a basic 3 layer configuration. Update the process to use Cross Validation\n","</p>"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":539,"status":"ok","timestamp":1683003685462,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"LuaHh7dfK_pj"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision.io import read_image\n"]},{"cell_type":"markdown","metadata":{"id":"4ayZvnueK_pk"},"source":["Configure this script as to whether it runs on Google Colab, or locally"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683003686280,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"vFtUm6uXK_pk"},"outputs":[],"source":["# When on Google Colab, running full training, change both to true. Locally, advised set both to false\n","isGoogleColab = False\n","useFullData = False"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2800,"status":"ok","timestamp":1683003689076,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"zzl3NpfVK_pk","outputId":"fb65a0b0-1895-411a-ff76-8cc7086526e5"},"outputs":[],"source":["# In local, the base directory is the current directory\n","baseDirectory = \"./\"\n","\n","if isGoogleColab:\n","    from google.colab import drive\n","    \n","    # If this is running on Google colab, assume the notebook runs in a \"COSC2673\" folder, which also contains the data files \n","    # in a subfolder called \"image_classification_data\"\n","    drive.mount(\"/content/drive\")\n","    !ls /content/drive/'My Drive'/COSC2673/\n","\n","    # Import the directory so that custom python libraries can be imported\n","    import sys\n","    sys.path.append(\"/content/drive/MyDrive/COSC2673/\")\n","\n","    # Set the base directory to the Google Drive specific folder\n","    baseDirectory = \"/content/drive/MyDrive/COSC2673/\""]},{"cell_type":"markdown","metadata":{"id":"vZCfUn3EK_pl"},"source":["Import the custom python files that contain reusable code"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683003689077,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"beWSdbauK_pl","outputId":"855961c1-7da8-4450-c7b3-3f9e66292cc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Seed: 266305\n"]}],"source":["import data_basic_utility as dbutil\n","import graphing_utility as graphutil\n","import statistics_utility as statsutil\n","\n","import a2_utility as a2util\n","import pytorch_utility as ptutil\n","from pytorch_utility import CancerBinaryDataset\n","from pytorch_utility import CancerCellTypeDataset\n","\n","\n","# randomSeed = dbutil.get_random_seed()\n","randomSeed = 266305\n","print(\"Random Seed: \" + str(randomSeed))"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683003689078,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"zgIXX9BXK_pl"},"outputs":[],"source":["# this file should have previously been created in the root directory\n","dfImages = pd.read_csv(baseDirectory + \"images_main.csv\")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683003689078,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"6_WFGagHK_pl","outputId":"f1ca6c45-d622-4dd2-91cb-adbd202a8b26"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>ImageName</th>\n","      <th>isCancerous</th>\n","      <th>cellType</th>\n","      <th>trainValTest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>./Image_classification_data/patch_images\\1.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>./Image_classification_data/patch_images\\10.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>./Image_classification_data/patch_images\\1000.png</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>./Image_classification_data/patch_images\\10000...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>./Image_classification_data/patch_images\\10001...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index                                          ImageName  isCancerous  \\\n","0      0     ./Image_classification_data/patch_images\\1.png            0   \n","1      1    ./Image_classification_data/patch_images\\10.png            0   \n","2      3  ./Image_classification_data/patch_images\\1000.png            1   \n","3      4  ./Image_classification_data/patch_images\\10000...            0   \n","4      5  ./Image_classification_data/patch_images\\10001...            0   \n","\n","   cellType  trainValTest  \n","0         0             0  \n","1         0             0  \n","2         2             0  \n","3         1             0  \n","4         1             0  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Get The training Split and the Validation Split together\n","dfImagesTrainVal = dfImages[(dfImages[\"trainValTest\"] == 0) | (dfImages[\"trainValTest\"] == 1)].reset_index()\n","dfImagesTrainVal.head()"]},{"cell_type":"markdown","metadata":{"id":"TZ1R94YdK_pn"},"source":["Note: The definition of the Custom Datasets for both the isCancerous data and the Cell Type data are defined in the pytorch_utility.py file.\n","\n","Also, rather than loading all the training images and calculating the mean and standard deviation values in here, that was run separately in file 05a.PyTorchGetMeanAndStd.ipynb\n","\n","Here we can just define the values to use, which shouldn't change unless the data is reloaded and a new train/validation/test split is generated"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.8035, 0.5909, 0.7640])\n","tensor([0.1246, 0.1947, 0.1714])\n"]}],"source":["train_mean, train_std = ptutil.getTrainMeanAndStdTensors()\n","print(train_mean)\n","print(train_std)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683003705777,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"I8z3yX8ZK_pn"},"outputs":[],"source":["# Create a tranform operation that also normalizes the images according to the mean and standard deviations of the images\n","transform_normalize = transforms.Compose(\n","    [transforms.ToPILImage(),\n","    transforms.ToTensor(), \n","    transforms.Normalize(train_mean, train_std)])\n"]},{"cell_type":"markdown","metadata":{"id":"F4jD7E2PK_po"},"source":["Now, create a class for the basic, Fully Connected Neural Network. For this basic NN, we will use 3 fully connected layers. The number of features in this will be 27 x 27 x 3, or 2187.\n","\n","Layer 1: Input is the images, which are 27 x 27 pixels, with 3 color values (RGB). Experiment initially with 1458 nodes\n","Layer 2: Input is 1458 from the the previous layer, down to 729\n","Layer 3: Input is 729 from the the previous layer, since this is a binary classification problem, the output will be 2 classes\n","\n","In this, we will use the **ReLU** Activation Function. This is the Rectified Linear Unit function, which allows the function to become non-linear"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683003705778,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"0two1S9gK_po"},"outputs":[],"source":["# Create a class for the Neural Network\n","class PT_NN_IsCancerous(nn.Module):\n","\n","    # In the constructor, initialize the layers to use\n","    def __init__(self):\n","        super(PT_NN_IsCancerous, self).__init__()\n","        self.fc1 = nn.Linear(27 * 27 * 3, 1458)\n","        self.fc2 = nn.Linear(1458, 729)\n","        self.fc3 = nn.Linear(729, 2)\n","\n","    # Create the forward function, which is used in training\n","    def forward(self, x):\n","        # process through each layer\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        # return the result\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"pO5dPhy6K_po"},"source":["Now train the Fully Connected Neural Network Model.\n","\n","During training, we will use the following:\n","- Softmax Cross Entropy Loss as our Loss function. This is a good Loss function that basically converts scores for each class into probabilities\n","- The Adam Optimizer, which is a version of Gradient Descent\n","- Initially, just 10 epochs"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272396,"status":"ok","timestamp":1683003978169,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"vQUAMyGuK_po","outputId":"d7e13864-910e-4876-d2c0-7ddfa9205ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","Fold 1:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","Fold 2:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","Fold 3:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","Fold 4:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","IsCancerous Binary Classification Results for Cell Type Predictions after K-Folds CV:\n","Average Accuracy Score: 0.7921763315573512\n","Average Precision Score: 0.6677420524869457\n","Average Recall Score: 0.9342260968081131\n","Average F1 Score: 0.7783222227965589\n"]}],"source":["# set the Learning Rate and Epochs to use\n","learning_rate = 0.0001 # Note: 0.00003 is too slow\n","epochsToUse = 10\n","\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","\n","kfolds = KFold(n_splits=5, random_state=randomSeed, shuffle=True)\n","\n","# Iterate over 5 splits of the data\n","for k, (train_index, vali_index) in enumerate(kfolds.split(dfImagesTrainVal)):\n","    print(\"Fold \" + str(k) + \":\")\n","    # Split the dataset between train and validation for this split\n","    dfImagesTrain = dfImagesTrainVal.iloc[train_index, ]\n","    dfImagesVal = dfImagesTrainVal.iloc[vali_index, ]\n","\n","    cancerous_training_data = None\n","\n","    #--------- Set up the data for training and validation\n","    # Create a custom Dataset for the training and validation data\n","    if useFullData:        \n","        dfImagesTrain = dfImagesTrain.reset_index()\n","        cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n","    else:\n","        # For testing in a small dataset\n","        dfImagesTrainTest = dfImagesTrain.iloc[range(200), :].reset_index()\n","        cancerous_training_data = CancerBinaryDataset(isGoogleColab, dfImagesTrainTest, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","    dfImagesVal = dfImagesVal.reset_index()\n","    cancerous_validation_data = CancerBinaryDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","    # Create data loaders\n","    cancerous_train_dataloader = DataLoader(cancerous_training_data, batch_size=32, shuffle=True, num_workers=2)\n","    cancerous_val_dataloader = DataLoader(cancerous_validation_data, batch_size=32, shuffle=True, num_workers=2)\n","\n","    #--------- Train the NN over 10 epochs\n","    net = PT_NN_IsCancerous()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    for epoch in range(epochsToUse):\n","        print(\"   Starting Epoch \" + str(epoch) + \"...\")\n","        for i, data in enumerate(cancerous_train_dataloader, 0):\n","            # Get the inputs\n","            inputs, labels = data\n","\n","            # This should convert the image tensors into vectors\n","            inputs = inputs.view(-1, 27 * 27 * 3)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Perform Forward and Backward propagation then optimize the weights\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    \n","    #--------- Predict on Validation and get the Evaluation Metric \n","    correct, total = 0,  0\n","    step=0\n","    predictions = []\n","\n","    # Set the Neural Network into evaluation (test) mode\n","    net.eval()\n","\n","    y_val_cancerous = []\n","    y_val_pred_cancerous = []\n","\n","    # Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n","    for i, data in enumerate(cancerous_val_dataloader, 0):\n","        inputs, labels = data\n","\n","        # This should convert the image tensors into vectors\n","        inputs = inputs.view(-1, 27 * 27 * 3)\n","\n","        outputs = net(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Loop through the batch, build the lists of the raw label and prediction values\n","        for j in range(len(labels)):\n","            y_val_cancerous.append(labels[j].item())\n","            y_val_pred_cancerous.append(predicted[j].item())\n","\n","        predictions.append(predicted)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    accuracy_scores.append(accuracy_score(y_val_cancerous, y_val_pred_cancerous))\n","    precision_scores.append(precision_score(y_val_cancerous, y_val_pred_cancerous))\n","    recall_scores.append(recall_score(y_val_cancerous, y_val_pred_cancerous))\n","    f1_scores.append(f1_score(y_val_cancerous, y_val_pred_cancerous))  \n","\n","\n","print(\"IsCancerous Binary Classification Results for Cell Type Predictions after K-Folds CV:\")\n","print(\"Average Accuracy Score: \" + str(np.mean(accuracy_scores)))\n","print(\"Average Precision Score: \" + str(np.mean(precision_scores)))\n","print(\"Average Recall Score: \" + str(np.mean(recall_scores)))\n","print(\"Average F1 Score: \" + str(np.mean(f1_scores)))      "]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.7914317925591883, 0.8043968432919955, 0.7609921082299888, 0.7913141567963903, 0.8127467569091935]\n"]}],"source":["print(accuracy_scores)"]},{"cell_type":"markdown","metadata":{"id":"fd9XOjhpK_pq"},"source":["Create a class for the Cell Type Neural Network model. The structure of the class will be fundamentally the same, only the model will need to output 4 classes"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683003980464,"user":{"displayName":"Nelson Cheng","userId":"13903294221993632929"},"user_tz":-600},"id":"eKOxU2-4K_pq"},"outputs":[],"source":["# Create a class for the Neural Network\n","class PT_NN_CellType(nn.Module):\n","\n","    # In the constructor, initialize the layers to use\n","    def __init__(self):\n","        super(PT_NN_CellType, self).__init__()\n","        self.fc1 = nn.Linear(27 * 27 * 3, 1458)\n","        self.fc2 = nn.Linear(1458, 729)\n","        self.fc3 = nn.Linear(729, 4)\n","\n","    # Create the forward function, which is used in training\n","    def forward(self, x):\n","        # process through each layer\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        # return the result\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"KRU0R9EMK_pq"},"source":["Now train the Fully Connected Neural Network Model. Use the same configuration (objective function, optimizer etc) as the Binary Classifier"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3FjNKScK_pq","outputId":"a741ad36-242b-40a6-ab2e-5cdb215fc283"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n","Fold 1:\n","   Starting Epoch 0...\n","   Starting Epoch 1...\n","   Starting Epoch 2...\n","   Starting Epoch 3...\n","   Starting Epoch 4...\n","   Starting Epoch 5...\n","   Starting Epoch 6...\n","   Starting Epoch 7...\n","   Starting Epoch 8...\n","   Starting Epoch 9...\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'append'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[34], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     91\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 93\u001b[0m accuracy_scores \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(accuracy_score(y_val_celltype, y_pred_celltype))\n\u001b[0;32m     94\u001b[0m precision_scores \u001b[38;5;241m=\u001b[39m precision_scores\u001b[38;5;241m.\u001b[39mappend(precision_score(y_val_celltype, y_pred_celltype, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     95\u001b[0m recall_scores \u001b[38;5;241m=\u001b[39m recall_scores\u001b[38;5;241m.\u001b[39mappend(recall_score(y_val_celltype, y_pred_celltype, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"]}],"source":["# set the Learning Rate and Epochs to use\n","learning_rate = 0.00003\n","epochsToUse = 10\n","\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","\n","kfolds = KFold(n_splits=5, random_state=randomSeed, shuffle=True)\n","\n","# Iterate over 5 splits of the data\n","for k, (train_index, vali_index) in enumerate(kfolds.split(dfImagesTrainVal)):\n","    print(\"Fold \" + str(k) + \":\")\n","\n","    # Split the dataset between train and validation for this split\n","    dfImagesTrain = dfImagesTrainVal.iloc[train_index, ]\n","    dfImagesVal = dfImagesTrainVal.iloc[vali_index, ]\n","    \n","    celltype_training_data = None\n","\n","    #--------- Set up the data for training and validation\n","    # Create a custom Dataset for the training and validation data\n","    if useFullData:\n","        dfImagesTrain = dfImagesTrain.reset_index()\n","        celltype_training_data = CancerCellTypeDataset(isGoogleColab, dfImagesTrain, baseDirectory, transform=transform_normalize)\n","    else:\n","        # For testing in a small dataset\n","        dfImagesTrainTest = dfImagesTrain.iloc[range(200), :].reset_index()\n","        celltype_training_data = CancerCellTypeDataset(isGoogleColab, dfImagesTrainTest, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","    dfImagesVal = dfImagesVal.reset_index()\n","    celltype_validation_data = CancerCellTypeDataset(isGoogleColab, dfImagesVal, baseDirectory, transform=transform_normalize, target_transform=None)\n","\n","    # Create data loaders\n","    celltype_train_dataloader = DataLoader(celltype_training_data, batch_size=32, shuffle=True, num_workers=2)\n","    celltype_val_dataloader = DataLoader(celltype_validation_data, batch_size=32, shuffle=True, num_workers=2)\n","\n","    #--------- Train the NN over 10 epochs\n","    net = PT_NN_CellType()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    for epoch in range(epochsToUse):\n","        print(\"   Starting Epoch \" + str(epoch) + \"...\")\n","        for i, data in enumerate(celltype_train_dataloader, 0):\n","            # Get the inputs\n","            inputs, labels = data\n","\n","            # This should convert the image tensors into vectors\n","            inputs = inputs.view(-1, 27 * 27 * 3)\n","\n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # Perform Forward and Backward propagation then optimize the weights\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","    \n","    #--------- Predict on Validation and get the Evaluation Metric \n","    correct, total = 0,  0\n","    step=0\n","    predictions = []\n","\n","    # Set the Neural Network into evaluation (test) mode\n","    net.eval()\n","\n","    y_val_celltype = []\n","    y_val_pred_celltype = []\n","\n","    # Looping through this dataloader essentially processes them in batches of 32 (or whatever the batchsize is configured in the data loader\n","    for i, data in enumerate(celltype_val_dataloader, 0):\n","        inputs, labels = data\n","\n","        # This should convert the image tensors into vectors\n","        inputs = inputs.view(-1, 27 * 27 * 3)\n","\n","        outputs = net(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Loop through the batch, build the lists of the raw label and prediction values\n","        for j in range(len(labels)):\n","            y_val_celltype.append(labels[j].item())\n","            y_val_pred_celltype.append(predicted[j].item())\n","\n","        predictions.append(predicted)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    accuracy_scores.append(accuracy_score(y_val_celltype, y_val_pred_celltype))\n","    precision_scores.append(precision_score(y_val_celltype, y_val_pred_celltype, average=\"micro\"))\n","    recall_scores.append(recall_score(y_val_celltype, y_val_pred_celltype, average=\"micro\"))\n","    f1_scores.append(f1_score(y_val_celltype, y_val_pred_celltype, average=\"micro\"))  \n","\n","\n","print(\"CellType Multi-class Classification Results for Cell Type Predictions after K-Folds CV:\")\n","print(\"Average Accuracy Score: \" + str(np.mean(accuracy_scores)))\n","print(\"Average Precision Score: \" + str(np.mean(precision_scores)))\n","print(\"Average Recall Score: \" + str(np.mean(recall_scores)))\n","print(\"Average F1 Score: \" + str(np.mean(f1_scores)))      "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"dcbc78149e46ccbab92a3f68a48c52feb0796c7e10dad8e3f1a2a5a780973376"}}},"nbformat":4,"nbformat_minor":0}
